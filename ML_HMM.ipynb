{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "e-5PCllPW4Rl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sujet HMM TP 1"
      ],
      "metadata": {
        "id": "pZ6kxI1QyxKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chaînes de Markov cachées (*Hidden Markov Models*, HMM)\n",
        "\n",
        "On suppose que vous avez un ami qui habite dans un autre pays que vous. Chaque jous, cet ami joue au tennis ou bien bulle dans son canapé, en fonction de la météo.\n",
        "\n",
        "Cependant, vous n'avez pas accès à la météo de ce pays, vous avez accès uniquement à l'information de ce qu'a fait votre ami (tennis ou canapé).\n",
        "\n",
        "On parle **d'observations** à propos des actions tennis/canapé, et **d'états cachés** pour la météo (3 états cachés ici).\n",
        "\n",
        "\n",
        "Un **modèle de Markov caché** est un **modèle de séquence de symboles (mots, caractères, tags, phonèmes...) avec de l'information manquante associée à chaque symbole : son état**.\n",
        "\n",
        "Notez que **la chaîne de Markov est définie sur les états cachés, pas sur les observations.**\n",
        "\n",
        "Il s'agit d'un **modèle joint entre des symboles observables et leurs catégories latentes/cachées/inconnues**.\n",
        "\n",
        "Des hypothèses simplificatrices fortes sous-tendent les HMM :\n",
        "\n",
        "\n",
        "\n",
        "*   Dépendance de l'état présent à l'état précédent (1er ordre) uniquement\n",
        "*   Stationnarité : les transitions entre états ne dépendent pas du temps\n",
        "*   Indépendance statistique des observations entre elles\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sitR_4nPIjwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce TP, nous reprenons l'exemple du cours, illustré dans cette figure.\n",
        "\n",
        "\n",
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/exemple_HMM_meteo_correct.png\" alt=\"chaine Markov\" width=\"800\"/>\n"
      ],
      "metadata": {
        "id": "pJt7rG7GIrLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous noterons les observations *canapé* et *tennis* $O_0$  et $O_1$, respectivement.\n",
        "\n",
        "Arbitrairement nous attribuons un indice à chaque état :\n",
        "\n",
        "\n",
        "*   *Pluie* : 0\n",
        "*   *Nuageux* : 1\n",
        "*   *Soleil* : 2\n",
        "\n",
        "On utilise les notations suivantes :\n",
        "\n",
        "*   $S_i$, avec $i=0,1,2$ pour désigner l'un de ces trois états.\n",
        "*   $S^t$, avec $t$ entier positif pour désigner l'état dans lequel on se trouve à l'instant $t$.\n",
        "\n",
        "\n",
        "Cet exemple est une chaîne de Markov dite d'ordre 1, au sens où la probabilité d'être dans l'état $S^t$ ne dépend que de l'état précédent $S^{t-1}$.\n",
        "\n",
        "\n",
        "Elle serait d'ordre 2, si cette probabilité dépendait de $S^{t-1}$ et $S^{t-2}$."
      ],
      "metadata": {
        "id": "mu8LvFbLeJqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** : donner la matrice de transition $A=[a_{ij}]$ de cet exemple.\n",
        "\n",
        "Les éléments de $A$ sont les probabilités conditionnelles de passer de l'état $S_j$ à l'état $S_i$ : $a_{ij}=P(S_i|S_j)$."
      ],
      "metadata": {
        "id": "qrfgtZ_pNa04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iuinLZk-Na0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff45c380-a284-430f-9b27-9cc70aa1f27c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.4000, 0.0000],\n",
              "        [0.3000, 0.2000, 0.3000],\n",
              "        [0.2000, 0.4000, 0.7000]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "A = torch.tensor([[0.5,0.4,0.0],[0.3,0.2,0.3],[0.2,0.4,0.7]])\n",
        "A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En plus de la matrice de transition (entre les états **cachés**), nous introduisons une deuxième matrice, la matrice des probabilités d'obervation que nous notons $B=[B_{ij}]$.\n",
        "\n",
        "Les éléments de $B$ sont les probabilités conditionnelles \"d'observer\" *tennis* ou *canapé*, en fonction d'un état caché $S_j$ :\n",
        "\n",
        "$B_{ij}=P(O_i|S_j)$\n",
        "\n",
        "Cette matrice s'appelle la **matrice d'émission**. Dans la figure, elle encode les probabilités des flêches rouges.\n",
        "\n",
        "**Question** : donner la matrice de transition $B=[a_{ij}]$ de cet exemple.\n"
      ],
      "metadata": {
        "id": "FGssuoch4LpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B =torch.tensor([[0.9,0.6,0.2],[0.1,0.4,0.8]])\n",
        "B"
      ],
      "metadata": {
        "id": "rg1Q8O9_ImiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97a46d2-96d1-450a-e384-8e452f6fe4c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9000, 0.6000, 0.2000],\n",
              "        [0.1000, 0.4000, 0.8000]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le HMM de notre exemple est entièrement caractérisé par $\\{A, B, \\boldsymbol \\pi\\}$. Regroupons tout dans cette cellule, en calculant les valeurs de $\\boldsymbol \\pi$, avec la méthode des valeurs propres par exemple."
      ],
      "metadata": {
        "id": "axlz_x1ooutF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L, V = torch.linalg.eig(A)\n",
        "pi0 = V[:,0]\n",
        "pi0 = pi0/torch.sum(pi0)\n",
        "pi0 = torch.real(pi0)\n",
        "\n",
        "if torch.allclose(pi0, torch.tensor([0.2182, 0.2727, 0.5091]), atol=1e-04):\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')\n",
        "\n",
        "print(pi0)\n",
        "# ces deux dict seront utiles par la suite\n",
        "state2ind = {\"Pluie\": 0, \"Nuageux\": 1, \"Soleil\": 2}\n",
        "ind2state = {0: \"Pluie\", 1: \"Nuageux\", 2: \"Soleil\"}\n",
        "\n",
        "obs2ind = {\"Canapé\": 0, \"Tennis\": 1}\n",
        "ind2obs = {0: \"Canapé\", 1: \"Tennis\"}"
      ],
      "metadata": {
        "id": "1AG4mc8zpI_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2e0b02-5303-4ffd-9232-4078ac34c80b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK !\n",
            "tensor([0.2182, 0.2727, 0.5091])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question** : générer une séquence aléatoire d'observations de longueur 5\n",
        "\n",
        "Pour cela, utiliser la fonction ```torch.multinomial()```\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.multinomial.html"
      ],
      "metadata": {
        "id": "sNqMIzAmoqdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratégie 1 : transition -> émission -> transition -> émission etc"
      ],
      "metadata": {
        "id": "_JNS17vIqWjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=5 # taille de la séquence que l'on veut\n",
        "seq = [] # liste qui va contenir les observations générées en mots\n",
        "\n",
        "# initialisation\n",
        "current_state = torch.multinomial(pi0, 1)\n",
        "\n",
        "col = B[:,current_state]\n",
        "print(col)\n",
        "\n",
        "# si on veut conserver la suite d'états (optionnel), créer cette liste\n",
        "seq_states = []\n",
        "\n",
        "for i in range(N):\n",
        "  # émission\n",
        "  seq.append(torch.multinomial(B[:,current_state], 1))\n",
        "  seq_states.append(current_state)\n",
        "\n",
        "  # transition\n",
        "  current_state = torch.multinomial(pi0, 1)\n",
        "\n",
        "print(seq)\n",
        "\n",
        "# optionnel\n",
        "print(seq_states)"
      ],
      "metadata": {
        "id": "LVskR4d9gP9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61c2ca7-ac17-4518-e98e-079d29a0af20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000],\n",
            "        [0.8000]])\n",
            "[tensor([[0],\n",
            "        [0]]), tensor([[0],\n",
            "        [0]]), tensor([[0],\n",
            "        [0]]), tensor([[0],\n",
            "        [0]]), tensor([[0],\n",
            "        [0]])]\n",
            "[tensor([2]), tensor([1]), tensor([2]), tensor([1]), tensor([2])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratégie 2 (optionnel) : générer une séquence d'états cachés entière puis générer une séquence d'observations"
      ],
      "metadata": {
        "id": "2wBLAaaPthJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq2 = []\n",
        "etats = torch.multinomial(pi0, 5, True)\n",
        "print(etats)\n",
        "\n",
        "for etat in etats :\n",
        "  seq2.append(torch.multinomial(B[:,etat], 1))\n",
        "\n",
        "print(seq2)"
      ],
      "metadata": {
        "id": "mDajnMR0sV9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adaa49b8-887f-4012-fc18-ef6022ba8eeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0, 1, 2])\n",
            "[tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probabilité d'une séquence d'observations données, lorsque la séquence d'états cachés associée est connue"
      ],
      "metadata": {
        "id": "awbCMvtptse0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\\begin{equation}\n",
        "P(O^0, \\ldots, O^{T-1}, S^0, \\ldots, S^{T-1}) = \\boldsymbol \\pi(S^0) \\, P(O^0|S^0)\\,Π_1^{T-1}\\,\\,P(S^{t}|S^{t-1})\\,P(O^t|S^T)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "EEpLmx47vFnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question"
      ],
      "metadata": {
        "id": "4oxrez_jkHQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reprendre le code de génération de séquence ci-dessus et compléter pour calculer la probabilité de la séquence générée."
      ],
      "metadata": {
        "id": "hC7y0rHFkNzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutoriel HMM : le tutoriel \"Rabiner\" (1989)"
      ],
      "metadata": {
        "id": "Yr3T31pvAf7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition* par Lawrence R. Rabiner, publié en 1989 dans Proc. of the IEEE.\n",
        "\n",
        "Une version est disponible ici : https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf\n",
        "\n",
        "Rabiner y décrit trois problèmes fondamentaux liés aux HMM :\n",
        "\n",
        "\n",
        "1.   **Évaluation**. Étant donnée une séquence d'observations $O = O^0, ..., O^{T-1}$, et un modèle HMM $\\lambda = \\{\\boldsymbol \\pi, A, B\\}$, comment peut-on calculer efficacement la probabilité $P(O|\\lambda)$ de la séquence $O$, étant donné le modèle ?\n",
        "\n",
        "2.   **Inférence ou décodage**. Étant donnée une séquence d'observations $O = O^0, ..., O^{T-1}$, et un modèle HMM $\\lambda = \\{\\boldsymbol \\pi, A, B\\}$, comment retrouver la séquence d'états $S = S^0, ..., S^{T-1}$ optimale pour expliquer la séquence d'observations $O$ ?\n",
        "\n",
        "3.   **Apprentissage**. comment ajuster les paramètres du modèle $\\lambda = \\{\\boldsymbol \\pi, A, B\\}$ pour maximiser la vraisemblance (likelihood) de données d'entraînement, c'est-à-dire maximiser $P(O|\\lambda)$.\n",
        "\n",
        "Ces trois problèmes font appel à des algorithmes très astucieux :\n",
        "\n",
        "1.   **Évaluation**. Algorithme *forward* (il existe aussi la version *backward*, utile pour le problème 3)\n",
        "2.   **Inférence ou décodage** : algorithme de *Viterbi*\n",
        "3.   **Apprentissage**. Deux situations possibles :\n",
        "\n",
        "      a.   Apprentissage supervisé : on a les séquences $O$ et $S$ correspondantes. Alors on utilise l'apprentissage par maximum de vraisemblance, qui donne des formules analytiques pour calculer $\\boldsymbol \\pi, A, B$ à partir des fréquences d'occurrences des observations et des états.\n",
        "      \n",
        "      b.   Apprentissage non-supervisé : on a des séquences $O$ mais pas $S$. Algorithme de type *Expectation-Maximization* (EM) appelé la méthode *Baum-Welch* dans le tutoriel.\n",
        "\n",
        "\n",
        "Les algorithmes *forward* et *Viterbi* sont des algorithmes de programmation dynamique, tout comme les algorithmes de distance de Levenshtein minimale, de recherche du plus court chemin de Dijkstra, etc.\n",
        "\n",
        "\n",
        "Dans ce TP, nous nous intéresserons seulement aux deux premiers problèmes de Rabiner, et coder les deux algorithmes *forward* et *Viterbi*. S'il reste du temps, il y a aussi en exercice le décodage *posterior*.\n",
        "\n"
      ],
      "metadata": {
        "id": "13Hk3_bmOEg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problème 1 : **Évaluation**, coder l'algorithme *forward*"
      ],
      "metadata": {
        "id": "eJJcF7PoOZOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étant donnée une séquence d'observations $O = O^0, ..., O^{T-1}$, et un modèle HMM $\\lambda = \\{\\boldsymbol \\pi, A, B\\}$, comment peut-on calculer efficacement la probabilité $P(O|\\lambda)$ de la séquence $O$, appelée vraisemblance ou *likelihood*, étant donné le modèle ?"
      ],
      "metadata": {
        "id": "9B1Xa9MKOhxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approche 1 : force brute (pas de code à écrire)"
      ],
      "metadata": {
        "id": "wJRbxniNR0Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Force brute : considérer toutes les séquences d'états valides, qui pourraient générer $O$ et sommer les probabilités correspondantes."
      ],
      "metadata": {
        "id": "IFJYIXW1R-MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considérons la séquence *Canapé -> Tennis*, lister tous les cas à envisager et les probabilités associées."
      ],
      "metadata": {
        "id": "3fujBoqhqB5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il y a NxN cas soit ici 9 cas. Si on note U pour Pluie, N pour Nuageux et S pour Soleil, on doit calculer :\n",
        "\n",
        "<!-- \\begin{eqnarray}\n",
        "P(01, UU) &=& \\boldsymbol \\pi(U)P(0|U)& P(U|U)P(1|U)\\\\\n",
        "P(01, UN) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(N|U)P(1|N)\\\\\n",
        "P(01, US) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(S|U)\\,\\,P(1|S)\\\\\n",
        "P(01, NU) &=& \\boldsymbol \\pi(N)P(0|N)& P(U|N)P(1|U)\\\\\n",
        "P(01, NN) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(N|N)P(1|N)\\\\\n",
        "P(01, NS) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(S|N)\\,\\,P(1|S)\\\\\n",
        "P(01, SU) &=& \\boldsymbol \\pi(S)P(0|S)& P(U|S)P(1|U)\\\\\n",
        "P(01, SN) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(N|S)P(1|N)\\\\\n",
        "P(01, SS) &=& \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & P(S|S)\\,\\,P(1|S)\\\\\n",
        "\\end{eqnarray} -->\n",
        "\n",
        "\n",
        "\\begin{eqnarray}\n",
        "P(01, UU) &=& \\boldsymbol \\pi(U)P(0|U)& P(U|U)P(1|U)\\\\\n",
        "P(01, NU) &=& \\boldsymbol \\pi(N)P(0|N) & P(U|N)P(1|U)\\\\\n",
        "P(01, SU) &=& \\boldsymbol \\pi(S)P(0|S) & P(U|S)\\,\\,P(1|U)\\\\\n",
        "P(01, UN) &=& \\boldsymbol \\pi(U)P(0|U)& P(N|U)P(1|N)\\\\\n",
        "P(01, NN) &=& \\boldsymbol \\pi(N)P(0|N) & P(N|N)P(1|N)\\\\\n",
        "P(01, SN) &=& \\boldsymbol \\pi(S)P(0|S) & P(N|S)\\,\\,P(1|N)\\\\\n",
        "P(01, US) &=& \\boldsymbol \\pi(U)P(0|U)& P(S|U)P(1|S)\\\\\n",
        "P(01, NS) &=& \\boldsymbol \\pi(N)P(0|N) & P(S|N)P(1|S)\\\\\n",
        "P(01, SS) &=& \\boldsymbol \\pi(S)P(0|S) & P(S|S)\\,\\,P(1|S)\\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "On voit des redondances. Posons :\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\alpha_U &=& \\boldsymbol \\pi(U)P(0|U)\\\\\n",
        "\\alpha_N &=& \\boldsymbol \\pi(N)P(0|N)\\\\\n",
        "\\alpha_S &=& \\boldsymbol \\pi(S)P(0|S)\\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "On a :\n",
        "\n",
        "\\begin{eqnarray}\n",
        "P(01, UU) &=& \\alpha_U & P(U|U)P(1|U)\\\\\n",
        "P(01, NU) &=& \\alpha_N & P(U|N)P(1|U)\\\\\n",
        "P(01, SU) &=& \\alpha_S & P(U|S)\\,\\,P(1|U)\\\\\n",
        "P(01, UN) &=& \\alpha_U & P(N|U)P(1|N)\\\\\n",
        "P(01, NN) &=& \\alpha_N & P(N|N)P(1|N)\\\\\n",
        "P(01, SN) &=& \\alpha_S & P(N|S)\\,\\,P(1|N)\\\\\n",
        "P(01, US) &=& \\alpha_U & P(S|U)P(1|S)\\\\\n",
        "P(01, NS) &=& \\alpha_N & P(S|N)P(1|S)\\\\\n",
        "P(01, SS) &=& \\alpha_S & P(S|S)\\,\\,P(1|S)\\\\\n",
        "\\end{eqnarray}\n",
        "\n",
        "\n",
        "\n",
        "Faisons les calculs"
      ],
      "metadata": {
        "id": "mvM0n10TqiWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_canape = pi0 * B[0]\n",
        "alpha_U = alpha_canape[0]\n",
        "alpha_N = alpha_canape[1]\n",
        "alpha_S = alpha_canape[2]\n",
        "print(alpha_canape)\n",
        "\n",
        "p1 = alpha_U * A[0,0] * B[1, 0]\n",
        "p2 = alpha_N * A[0,1] * B[1, 0]\n",
        "p3 = alpha_S * A[0,2] * B[1, 0]\n",
        "\n",
        "p4 = alpha_U * A[1,0] * B[1, 1]\n",
        "p5 = alpha_N * A[1,1] * B[1, 1]\n",
        "p6 = alpha_S * A[1,2] * B[1, 1]\n",
        "\n",
        "p7 = alpha_U * A[2,0] * B[1, 2]\n",
        "p8 = alpha_N * A[2,1] * B[1, 2]\n",
        "p9 = alpha_S * A[2,2] * B[1, 2]\n",
        "\n",
        "p = p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9\n",
        "print(\"Probabilité d'observer Canapé -> Tennis : {:.3f}\".format(p))"
      ],
      "metadata": {
        "id": "Hfi0TuRmyCVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c961b3-62ab-41a8-d148-3d506ec02189"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1964, 0.1636, 0.1018])\n",
            "Probabilité d'observer Canapé -> Tennis : 0.206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bilan"
      ],
      "metadata": {
        "id": "B7mIcTpSqMwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pour une séquence de longueur $T$ et $N$ états cachés, le nombre de multiplications à faire pour calculer cette probabilité est de l'ordre de $2TN^T$.\n",
        "\n",
        "Autrement dit, la complexité est $O(N^T)$, soit exponentielle par rapport au nombre d'états cachés.\n",
        "\n",
        "Il faut donc faire autrement..."
      ],
      "metadata": {
        "id": "AT3vIOlJpx6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approche 2 : l'algorithme forward (à vous de jouer)"
      ],
      "metadata": {
        "id": "6KWuiIkDSY2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si l'on énumère les séquences d'états possibles pour générer une séquence d'observation, on s'aperçoit qu'il y a beaucoup de calculs en commun, et donc redondants.\n",
        "\n",
        "L'algorithme *forward* est un algorithme de programmation dynamique.\n",
        "\n",
        "Il utilise une variable intermédiaire appelée $\\alpha$ :\n",
        "\n",
        "$\\alpha^t(S_i)$ est la probabilité jointe de la séquence partielle d'observations $O^0, \\ldots, O^t$ tout en étant dans l'état $S_i$ à l'instant $t$ :\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha^t(S_i) = P(O^0, \\ldots, O^t, S^t=S_i)\n",
        "\\end{equation}\n",
        "\n",
        "L'algorithme *forward* est le suivant :\n",
        "\n",
        "\n",
        "\n",
        "*   Initialisation\n",
        "\n",
        "   *   Pour tous les états $i=0\\ldots N-1$, poser :\n",
        "      \\begin{equation}\n",
        "        \\alpha^0(S_i) = \\boldsymbol \\pi_i P(O^0|S_i)\n",
        "      \\end{equation}\n",
        "\n",
        "      À noter que $P(O^0|S_i)$ est un élément de la matrice d'émission $B$.\n",
        "\n",
        "*   Récurrence/induction\n",
        "\n",
        "    *   Pour les itérations suivantes, d'indices $t=1\\ldots T-1 $, et pour les $N$ états $i=0\\ldots N-1$, calculer :\n",
        "\n",
        "      \\begin{eqnarray}\n",
        "          \\alpha^t(S_i) &=& \\sum_{j=0}^{N-1} \\alpha^{t-1}(S_j)\\,P(S_i|S_j)\\,P(O^t|S_i)\\\\\n",
        "           &=& P(O^t|S_i) \\sum_{j=0}^{N-1} \\alpha^{t-1}(S_j)\\,P(S_i|S_j)\n",
        "      \\end{eqnarray}\n",
        "\n",
        "*   Terminaison\n",
        "\n",
        "    *   On obtient finalement la probabilité de la séquence complète :\n",
        "\n",
        "        \\begin{equation}\n",
        "          P(O) = \\sum_{j=0}^{N-1} \\alpha^{T-1}(S_j)\n",
        "        \\end{equation}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zMgAceZgv-bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/forward.png\" alt=\"forward\" width=\"300\"/>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OgwO2cmjvxKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Coder une première version \"naïve\", avec des boucles *for* imbriquées pour l'étape d'induction.\n",
        "\n",
        "Votre fonction prend en entrée une séquence d'observations et les paramètres du modèle, et retourne la probabilité de la séquence."
      ],
      "metadata": {
        "id": "VZrTNWiERSlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_naif(seq, A, B, pi0):\n",
        "    # seq : sequence d'observations, liste d'entiers\n",
        "    # A : matrice de transition N x N où N nb d'états cahcés\n",
        "    # B : matrice d'émission O x N où O nb d'observations possibles différentes\n",
        "    # pi0: vecteur distribution stationnaire des N états cachés\n",
        "\n",
        "    T = len(seq) # longueur de la seq\n",
        "    N = A.size(0) # nb d'états cachés\n",
        "\n",
        "    # initialisation\n",
        "    alpha = torch.zeros(N,T)\n",
        "    for i in range(N):\n",
        "      alpha[i,0] = pi0[i] * B[seq[0], i]\n",
        "\n",
        "    # induction\n",
        "    for t in range(1, T):\n",
        "        for i in range(N):\n",
        "          alpha[i,t] = torch.sum(alpha[:,t-1]*A[:, i]) * B[seq[t], i]\n",
        "\n",
        "    # terminaison\n",
        "    res = torch.sum(alpha[:,T - 1])\n",
        "    return res"
      ],
      "metadata": {
        "id": "SSc9JmTVtq9T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester votre fonction :"
      ],
      "metadata": {
        "id": "yZtoEuR4hqD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_obs = [0,1]\n",
        "seq_obs_mots = [ind2obs[i] for i in seq_obs]\n",
        "\n",
        "p = forward_naif(seq_obs, A, B, pi0)\n",
        "print(\" -> \".join(seq_obs_mots))\n",
        "print(\"Probabilité : {:.3f}\".format(p))\n",
        "\n",
        "if torch.isclose(p, torch.tensor(0.206), atol=1e-03):\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')"
      ],
      "metadata": {
        "id": "Q61HLiPpiJJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe01060-99a9-4be2-9941-4abcd1287f40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canapé -> Tennis\n",
            "Probabilité : 0.174\n",
            "KO !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Amélioration\n",
        "\n",
        "Dans l'étape d'induction, ne garder que la boucle sur les éléments de la séquence et remplacer les autres boucles imbriquées par un produit matriciel."
      ],
      "metadata": {
        "id": "1agTiQBkRhNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(seq, A, B, pi0):\n",
        "    # seq : séquence d'observations, liste d'entiers\n",
        "    # A : matrice de transition N x N où N est le nombre d'états cachés\n",
        "    # B : matrice d'émission O x N où O est le nombre d'observations possibles\n",
        "    # pi0 : vecteur distribution initiale des N états cachés\n",
        "\n",
        "    T = len(seq)  # longueur de la séquence d'observations\n",
        "    N = A.size(0)  # nombre d'états cachés\n",
        "\n",
        "    # initialisation de alpha pour toute la séquence (N,)\n",
        "    alpha = torch.zeros(N, T)\n",
        "\n",
        "    # Initialisation : alpha[:, 0] = pi0 * B[O0, :]\n",
        "    alpha[:, 0] = pi0 * B[seq[0], :]\n",
        "\n",
        "    # induction avec produit matriciel\n",
        "    for t in range(1, T):\n",
        "        # alpha_t = (alpha_t-1 @ A) * B[Ot, :]\n",
        "        alpha[:, t] = (alpha[:, t - 1] @ A) * B[seq[t], :]\n",
        "\n",
        "    # terminaison : P(O) = sum_j alpha_j(T-1)\n",
        "    res = torch.sum(alpha[:, T - 1])\n",
        "\n",
        "    return res\n",
        "\n"
      ],
      "metadata": {
        "id": "76FqasaglPvT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester votre fonction"
      ],
      "metadata": {
        "id": "YYNsIei9_IrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_obs = [0,1]\n",
        "seq_obs_mots = [ind2obs[i] for i in seq_obs]\n",
        "\n",
        "p = forward(seq_obs, A, B, pi0)\n",
        "print(\" -> \".join(seq_obs_mots))\n",
        "print(\"Probabilité : {:.3f}\".format(p))\n",
        "\n",
        "if torch.isclose(p, torch.tensor(0.206), atol=1e-03):\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')"
      ],
      "metadata": {
        "id": "_s6td6obCrs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71938244-5d24-4c02-94d6-89441597a91c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canapé -> Tennis\n",
            "Probabilité : 0.174\n",
            "KO !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester votre fonction sur une séquence plus longue"
      ],
      "metadata": {
        "id": "T0F-bQ-6_NND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_obs = [0,1,1,1,0,0]\n",
        "\n",
        "seq_obs_mots = [ind2obs[i] for i in seq_obs]\n",
        "\n",
        "p = forward(seq_obs, A, B, pi0)\n",
        "print(\" -> \".join(seq_obs_mots))\n",
        "print(\"Probabilité : {:.3f}\".format(p))\n",
        "\n",
        "if torch.isclose(p, torch.tensor(0.014), atol=1e-03):\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')\n"
      ],
      "metadata": {
        "id": "KkeUcnTb_Pnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1512632e-9061-43f5-8496-8cf60db505ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canapé -> Tennis -> Tennis -> Tennis -> Canapé -> Canapé\n",
            "Probabilité : 0.018\n",
            "KO !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** : pourquoi est-ce que la probabilité de cette séquence est plus petite que celle de la séquence précédente ?"
      ],
      "metadata": {
        "id": "njkoBwPXAW7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La complexité de cet algorithme est $O(N^2T)$, bien mieux que $O(N^T)$ !!"
      ],
      "metadata": {
        "id": "ztU05ieEWJ_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problème 2 : **Inférence ou décodage**"
      ],
      "metadata": {
        "id": "S34zYU5szeFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemple tennis ou canap'?\n",
        "\n",
        "Nous souhaitons écrire un algorithme qui remplisse le tableau suivant avec les scores de chaque case, ainsi que, dans une deuxième temps, l'état d'où l'on vient à l'instant d'avant, pour obtenir la séquence d'états optimale.\n",
        "\n",
        "En effet, ce qui nous intéresse dans le décodage, c'est d'obtenir la séquence de prédictions des états cachés."
      ],
      "metadata": {
        "id": "IO_OYF1tobMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/viterbi_meteo.png\" alt=\"viterbi\" width=\"800\"/>"
      ],
      "metadata": {
        "id": "NXTrkMHypocL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemple de cas d'usage : en traitement de données textuelles (*NLP* pour *Natural Language Processing*), trouver les tags Part-Of-Speech des mots d'une phrase (*POS tagging*) :"
      ],
      "metadata": {
        "id": "GkzIDZ7SpjXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/problem2_exemple_POS_tagging.png\" alt=\"viterbi\" width=\"800\"/>\n",
        "\n",
        "4000 séquences d'états possibles sur ce petit exemple !\n",
        "\n",
        "(Image de Noah Smith)"
      ],
      "metadata": {
        "id": "VFmZE09FpsqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formulation"
      ],
      "metadata": {
        "id": "6CN-7wJopvqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étant donnée une séquence d'observations $O = O^0, ..., O^{T-1}$, et un modèle HMM $\\lambda = \\{\\boldsymbol \\pi, A, B\\}$, comment retrouver la séquence d'états $S = S^0, ..., S^{T-1}$ optimale pour expliquer la séquence d'observations $O$ ?\n",
        "\n",
        "\n",
        "Nous pourrions vouloir simplement choisir l'état le plus vraisemblable à chaque temps $t$, indépendamment des états précédents ou suivants : selon $P(S^t=S_i|O)$. Ce serait très efficace, mais cela peut donner des séquences non-valides, si par exemple il y a des probabilités de transition nulles dans le modèle.\n",
        "\n",
        "L'algorithme de référence est l'algorithme Viterbi, qui est un algorithme de programmation dynamique.\n",
        "\n"
      ],
      "metadata": {
        "id": "i6ZPtLPez5ES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viterbi (scores seulement)"
      ],
      "metadata": {
        "id": "e3m9Qr5391CZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons calculer à chaque temps $t$, le meilleur score (plus grande vraisemblance) d'un unique meilleur chemin, qui rend compte des $t$ premières observations, et qui aboutit à l'état $S_i$ au temps $t$. Dans le tutoriel Rabiner, ce score est noté par la lettre grecque delta :\n",
        "\n",
        "\\begin{equation}\n",
        "\\delta^t(S_i) = \\max_{S^0, S^1, \\ldots, S^{t-1}} P(S^0, O^0, S^1, O^1, \\ldots, S^t=S_i, O^t)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "*   Initialisation\n",
        "\n",
        "   *   Pour tous les états $i=0\\ldots N-1$, poser :\n",
        "      \\begin{equation}\n",
        "        \\delta^0(S_i) = \\boldsymbol \\pi_i P(O^0|S_i)\n",
        "      \\end{equation}\n",
        "\n",
        "      À noter que $P(O^0|S_i)$ est un élément de la matrice d'émission $B$.\n",
        "\n",
        "*   Récurrence/induction\n",
        "\n",
        "    *   Pour les itérations suivantes, d'indices $t=1\\ldots T-1 $, et pour les $N$ états $i=0\\ldots N-1$, calculer :\n",
        "\n",
        "      \\begin{eqnarray}\n",
        "          \\delta^t(S_i) &=& \\max_{j=0\\ldots N-1} \\delta^{t-1}(S_j)\\,P(S_i|S_j)\\,P(O^t|S_i)\\\\\n",
        "           &=& P(O^t|S_i) \\max_{j=0\\ldots N-1} \\delta^{t-1}(S_j)\\,P(S_i|S_j)\n",
        "      \\end{eqnarray}\n",
        "\n",
        "*   Terminaison\n",
        "\n",
        "    *   On obtient finalement le score de la séquence la plus vraisemblable des états :\n",
        "\n",
        "        \\begin{equation}\n",
        "          \\text{score}^{T-1} = P(S^*|O) = \\max_{j=0\\ldots N-1} \\delta^{T-1}(S_j)\n",
        "        \\end{equation}\n",
        "\n"
      ],
      "metadata": {
        "id": "DpdRf3im95Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemple POS tagging"
      ],
      "metadata": {
        "id": "llTmUGlrvEi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/viterbi_example_POS_scores.png\" alt=\"viterbi POs example\" width=\"800\"/>\n",
        "\n",
        "\n",
        "(Image de Noah Smith)"
      ],
      "metadata": {
        "id": "Awv1ymRBvJfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code **Exercice**\n",
        "\n",
        "Votre fonction prend en entrée une séquence d'observations et les paramètres du modèle, et retourne le score de la séquence."
      ],
      "metadata": {
        "id": "FQWvKt7qoeU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_score(seq, A, B, pi0):\n",
        "    # seq : sequence d'observations, liste d'entiers\n",
        "    # A : matrice de transition N x N où N nb d'états cahcés\n",
        "    # B : matrice d'émission O x N où O nb d'observations possibles différentes\n",
        "    # pi0: vecteur distribution stationnaire des N états cachés\n",
        "\n",
        "    T = len(seq) # longueur de la seq\n",
        "    N = A.size(0) # nb d'états cachés\n",
        "\n",
        "    # Initialisation de delta pour toute la séquence (N x T)\n",
        "    delta = torch.zeros(N, T)\n",
        "\n",
        "    # initialisation\n",
        "    for etat in range(N):\n",
        "            delta[etat, 0] = pi0[etat] * B[seq[0], etat]\n",
        "\n",
        "    # Induction : Pour chaque instant t=1 à T-1\n",
        "    for t in range(1, T):\n",
        "        for etat in range(N):\n",
        "            # delta_t(Si) = max_j(delta_t-1(Sj) * A[Sj, Si]) * B[Ot, Si]\n",
        "            delta[etat, t] = torch.max(delta[:, t - 1] * A[:, etat]) * B[seq[t], etat]\n",
        "\n",
        "    # terminaison\n",
        "    res = torch.max(delta[:, T - 1])\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "rMYKVyJhmIGv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_obs = [0,1]\n",
        "seq_obs_mots = [ind2obs[i] for i in seq_obs]\n",
        "\n",
        "score = viterbi_score(seq_obs, A, B, pi0)\n",
        "print(\" -> \".join(seq_obs_mots))\n",
        "print(\"Score Viterbi : {:.3f}\".format(score))\n",
        "\n",
        "if torch.isclose(score, torch.tensor(0.057), atol=1e-03):\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')"
      ],
      "metadata": {
        "id": "UjMui-JHmOO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec5d8f8-677b-4ca4-a2c0-c4482f3610e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canapé -> Tennis\n",
            "Score Viterbi : 0.057\n",
            "OK !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question : est-ce qu'on n'a pas fait la même chose déjà avec l'algorithme *forward* ?**"
      ],
      "metadata": {
        "id": "oGa39Goou4_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/diff_forward_viterbi.png\" alt=\"chaine Markov\" width=\"500\"/>\n"
      ],
      "metadata": {
        "id": "cvVBzb7Au68N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viterbi (scores et séquence d'états)\n",
        "\n",
        "Viterbi nous donne le score du meilleur chemin, mais comment avoir les prédictions (la séquence d'états cachés) qui correspondent ?"
      ],
      "metadata": {
        "id": "B4qDh4o_vKz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lors du calcul des scores par induction, à chaque temps $t$, il faut conserver l'identité de l'état dont le score est maximal.\n",
        "\n",
        "Ces états seront notés $\\text{bp}$ pour *backpointers* en anglais.\n",
        "\n",
        "Voici l'algo complété.\n",
        "\n",
        "*   Initialisation\n",
        "\n",
        "   *   Pour tous les états $i=0\\ldots N-1$, poser :\n",
        "      \\begin{equation}\n",
        "        \\delta^0(S_i) = \\boldsymbol \\pi_i P(O^0|S_i)\n",
        "      \\end{equation}\n",
        "\n",
        "      À noter que $P(O^0|S_i)$ est un élément de la matrice d'émission $B$.\n",
        "\n",
        "*   Récurrence/induction\n",
        "\n",
        "    *   Pour les itérations suivantes, d'indices $t=1\\ldots T-1 $, et pour les $N$ états $i=0\\ldots N-1$, calculer :\n",
        "\n",
        "      \\begin{eqnarray}\n",
        "          \\delta^t(S_i) &=& \\max_{j=0\\ldots N-1} \\delta^{t-1}(S_j)\\,P(S_i|S_j)\\,P(O^t|S_i)\\\\\n",
        "           &=& P(O^t|S_i) \\max_{j=0\\ldots N-1} \\delta^{t-1}(S_j)\\,P(S_i|S_j)\n",
        "      \\end{eqnarray}\n",
        "    \n",
        "    * Déterminer quel est l'état au temps précédent qui a maximisé le score :   \n",
        "    \\begin{equation}\n",
        "        \\text{bp}^t(S_i) = \\text{arg max}_{j=0\\ldots N-1} \\delta^{t-1}(S_j)\\,P(S_i|S_j)\n",
        "    \\end{equation}\n",
        "\n",
        "*   Terminaison\n",
        "\n",
        "    *   On obtient finalement la probabilité de la séquence complète :\n",
        "\n",
        "        \\begin{equation}\n",
        "          P^*(O) = \\max_{j=0\\ldots N-1} \\delta^{T-1}(S_j)\n",
        "        \\end{equation}\n",
        "    \n",
        "    *   Et l'état optimal :\n",
        "    \\begin{equation}\n",
        "        \\text{bp}^{T-1}(S_i) = \\text{arg max}_{j=0\\ldots N-1} \\delta^{T-2}(S_j)\\,P(S_i|S_j)\n",
        "    \\end{equation}\n",
        "\n",
        "\n",
        "Puis pour récupérer le meilleur chemin d'états (*Backtracing*) :\n",
        "\n",
        "   *   On choisit l'état appelé $S^{T-1}_*$ qui maximise $\\delta^{T-1}$.\n",
        "   *   Puis à l'instant $t$ précédent prendre : $S^{T-2} = \\text{bp}^{T-1}(S^{T-1}_*)$.\n",
        "   *   De manière générale, $S^{t-1} = \\text{bp}^{t}(S^{t}_*)$.\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "BV9GHXdXbAJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemple POS tagging\n"
      ],
      "metadata": {
        "id": "mlcixAv9taUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M2ML2/cours2/viterbi_example_POS.png\" alt=\"viterbi POs example\" width=\"800\"/>\n",
        "\n",
        "\n",
        "(Image de Noah Smith)"
      ],
      "metadata": {
        "id": "e8NaSnlftmu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code **exercice**"
      ],
      "metadata": {
        "id": "TVJLvlmsttbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour le backtracing, vous utiliserez la fonction ```torch.argmax()``` :\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.argmax.html"
      ],
      "metadata": {
        "id": "LCgB2tZ0Gb6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_complet(seq, A, B, pi0):\n",
        "    # seq : séquence d'observations, liste d'entiers\n",
        "    # A : matrice de transition N x N où N est le nombre d'états cachés\n",
        "    # B : matrice d'émission O x N où O est le nombre d'observations possibles\n",
        "    # pi0 : vecteur distribution initiale des N états cachés\n",
        "\n",
        "    T = len(seq)  # longueur de la séquence d'observations\n",
        "    N = A.size(0)  # nombre d'états cachés\n",
        "\n",
        "    # Initialisation de delta et des backpointers\n",
        "    delta = torch.zeros(N, T)\n",
        "    bp = torch.zeros(T, N, dtype=torch.int64)\n",
        "\n",
        "    # Initialisation : delta_0(Si) = pi0[i] * B[O0, Si]\n",
        "    for etat in range(N):\n",
        "        delta[etat, 0] = pi0[etat] * B[seq[0], etat]\n",
        "\n",
        "    # Induction : Pour chaque instant t=1 à T-1\n",
        "    for t in range(1, T):\n",
        "        for etat in range(N):\n",
        "            # Calcul des scores intermédiaires pour l'état `etat` à l'instant t\n",
        "            scores = delta[:, t - 1] * A[:, etat]\n",
        "            delta[etat, t] = torch.max(scores) * B[seq[t], etat]\n",
        "            # Stocker l'indice de l'état précédent qui maximise le score\n",
        "            bp[t, etat] = torch.argmax(scores)\n",
        "\n",
        "    # Terminaison : Score final = max_j(delta_T-1(Sj))\n",
        "    res = torch.max(delta[:, T - 1])\n",
        "    best_last_state = torch.argmax(delta[:, T - 1])\n",
        "\n",
        "    # Backtracing pour retrouver le chemin optimal\n",
        "    viterbi_seq = [best_last_state.item()]  # Commencer par l'état final\n",
        "    for t in range(T - 1, 0, -1):  # Remonter dans le temps de T-1 à 1\n",
        "        best_state = bp[t, viterbi_seq[-1]]  # Choisir l'état précédent\n",
        "        viterbi_seq.append(best_state.item())\n",
        "\n",
        "    # Remettre viterbi_seq dans l'ordre t=0...T-1 :\n",
        "    viterbi_seq.reverse()\n",
        "\n",
        "    return res, viterbi_seq"
      ],
      "metadata": {
        "id": "sJ-wobAwdVxv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_obs = [0,1,1,1,0,0]\n",
        "seq_obs = [0,1]\n",
        "seq_obs_mots = [ind2obs[i] for i in seq_obs]\n",
        "\n",
        "score, seq_etats = viterbi_complet(seq_obs, A, B, pi0)\n",
        "print(\" -> \".join(seq_obs_mots))\n",
        "print(\"Score : {:.5f}\".format(score))\n",
        "seq_etats_mots = [ind2state[i] for i in seq_etats]\n",
        "print(\"Séquence d'états Viterbi : \", \" -> \".join(seq_etats_mots))\n",
        "\n",
        "if seq_etats == [0,2]:\n",
        "  print('OK !')\n",
        "else:\n",
        "  print('KO !')\n"
      ],
      "metadata": {
        "id": "wIhXba2dlrOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c8902e-b307-440e-9162-5209a07ab502"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canapé -> Tennis\n",
            "Score : 0.05702\n",
            "Séquence d'états Viterbi :  Soleil -> Soleil\n",
            "KO !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVZqEdIbfh62"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}